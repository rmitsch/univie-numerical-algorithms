{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Algorithms - Homework Assignment 1\n",
    "Due to 24.04.2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** _(0.5 points)_ The IEEE standard 754 (known as the \"floating-point standard\") specifies the 128-bit word as having 15 bits for the exponent.\n",
    "\n",
    " * What is the length of the fraction (mantissa)? What is the machine epsilon?  \n",
    " * How many significant decimal digits does this word have?  \n",
    " * Why is quadruple precision more than twice as accurate as double precision, which is in turn more than twice as accurate as single precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "* Length of the mantissa is 112 bit. Machine epsilon is $\\epsilon = 2^{-113}$. ([Source](https://en.wikipedia.org/wiki/Quadruple-precision_floating-point_format))\n",
    "* $log_{10}(2^{113}) = 34.01..$ - a 128-bit word in the IEEE standard has approximately 34 significant decimal digits. According to [1], due to the leading exponent bit (that might be zero) and whether input/output is a decimal string or a IEEE 754-compliant quadruple-precision number, between 33 and 36 significant decimal digits are possible.\n",
    "* Because the correlation between the number of significant digits (which is approximately doubled from half- to single- to double-...precision) and the resulting precision is exponential and not linear w.r.t. to the number of available bits/digits - see equation for the calculation of the machine epsilon.\n",
    "\n",
    "[1] _William Kahan (1 October 1987). \"Lecture Notes on the Status of IEEE Standard 754 for Binary Floating-Point Arithmetic\"_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** _(1 point)_ The IEEE standard 754 specifies that all arithmetic operations are to be\n",
    "performed as if they were first calculated to infinite precision and then rounded\n",
    "according to one of four modes. The default rounding mode is to round to the\n",
    "nearest representable number, with rounding to even (zero least significant bit) in\n",
    "the case of a tie.\n",
    "\n",
    "Which of the following statements is true in IEEE arithmetic, assuming that a and\n",
    "b are normalized floating point numbers and that no exception occurs in the stated\n",
    "operations? In each case, give a short explanation.   \n",
    "  \n",
    "a) $fl(a\\;op\\;b) = fl(b\\;op\\;a);\\;op = +;\\;∗:$  \n",
    "b) $fl(a + a) = fl(2 ∗ a)$  \n",
    "c) $fl((a + b) + c) = fl(a + (b + c))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "a) True, since both specified operations are commutative and there are no intermediate rounding steps.  \n",
    "b) True, since both expressions are equivalent and there aren't any intermediate rounding steps.  \n",
    "c) False. Consider that $fl(x\\;op\\;y) = (x\\;op\\;y)(1 + \\delta)$. In the left-hand side expression $a$ is involved indirectly in two rounding operations, $c$ in one; in the right-hand side expression the other way around. According to the accuracy model before the left-hand side expression yields to an forward error of  \n",
    "$$\n",
    "fl((a + b) + c) = ((a + b)(1 + \\delta) + c)(1 + \\delta) = ((a + b)(1 + \\delta)^2 + c(1 + \\delta))\n",
    "$$\n",
    "while the right-hand side expression yields\n",
    "$$\n",
    "fl(a + (b + c)) = (a + (b + c)(1 + \\delta))(1 + \\delta) = (a(1 + \\delta) + (b + c)(1 + \\delta)^2)\n",
    "$$  \n",
    "Therefore: If $a > c$, the right-hand side expression leads to a smaller forward error; if $c > a$, the left-hand side expression.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** _(2.5 points)_ Using the standard model of floating point arithmetic introduced in the lecture, derive forward and backward error bounds for a simple summation, in which the $x_i$ are machine numbers and the sum is evaluated from left to right<sup>1</sup>.\n",
    "\n",
    "<sup>1</sup>: E.g. $S_4 = ((x_1 + x_2) + x_3) + x_4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Note that we...\n",
    "* ...follow the procedure presented in Lecture 2 (Error Analysis).\n",
    "* ...assume that $\\delta_1 = \\delta_2 = ... \\delta_n = \\delta$.\n",
    "\n",
    "We first introduce the base case:\n",
    "$$\n",
    "\\hat{s}_1 = fl(x_1 + x_2) = (x_1 + x_2)(1 \\pm \\delta)\n",
    "$$\n",
    "Calculation of steps 2 and 3:\n",
    "$$\n",
    "\\begin{align} \n",
    "\\hat{s}_2 &= fl(\\hat{s}_1 + x_3) = ((x_1 + x_2)(1 \\pm \\delta) + x_3)(1 \\pm \\delta) = (x_1 + x_2)(1 \\pm \\delta)^2 + x_3(1 \\pm \\delta) \\\\\n",
    "\\hat{s}_3 &= fl(\\hat{s}_2 + x_4) = (\\hat{s}_2 + x_4)(1 \\pm \\delta) = \\hat{s}_2(1 \\pm \\delta) + x_4(1 \\pm \\delta) = (x_1 + x_2)(1 \\pm \\delta)^3 + x_3(1 \\pm \\delta)^2 + x_4(1 \\pm \\delta)\n",
    "\\end{align} \n",
    "$$\n",
    "  \n",
    "We conclude therefore that the following generalization holds:\n",
    "$$\n",
    "\\hat{s}_n = (x_1 + x_2)(1\\pm\\delta)^n + x_3(1\\pm\\delta)^{n-1} + x_4(1\\pm\\delta)^{n-2} + ... +  + x_n(1\\pm\\delta)^{1}\n",
    "$$\n",
    "\n",
    "Assuming lemma\n",
    "$$\n",
    "\\begin{align}\n",
    "\\prod\\limits_{i = 1}^{n}(1 \\pm \\delta)^{\\rho i} &= 1 + \\theta_n \\\\\n",
    "\\lvert \\theta_n \\rvert  \\leq \\frac{n\\epsilon_m}{1 - n\\epsilon_m} &=: \\gamma_n\n",
    "\\end{align}\n",
    "$$\n",
    "is applicable, we can simplify our **backwards error result** to\n",
    "$$\n",
    "\\hat{s}_n = (x_1 + x_2)(1 + \\theta_n) + x_3(1 + \\theta_{n-1}) + x_4(1 + \\theta_{n-2}) + ... +  + x_n(1 + \\theta_{1})\n",
    "$$\n",
    "  \n",
    "Our **absolute/relative forward error bound** is\n",
    "$$\n",
    "\\begin{align}\n",
    "afe &=\\lvert \\sum\\limits_{i = 1}^{n}x_i - fl(\\sum\\limits_{i = 1}^{n}x_i) \\rvert \\leq \\gamma_n \\sum\\limits_{i = 1}^{n} \\lvert x_i \\rvert \\\\\n",
    "rfe &= \\frac{\\lvert \\sum\\limits_{i = 1}^{n}x_i - fl(\\sum\\limits_{i = 1}^{n}x_i) \\rvert}{\\sum\\limits_{i = 1}^{n}\\lvert x_i \\rvert} \\leq \\frac{\\gamma_n \\sum\\limits_{i = 1}^{n} \\lvert x_i \\rvert}{\\sum\\limits_{i = 1}^{n}\\lvert x_i \\rvert}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programming Exercise\n",
    "\n",
    "The task is to implement an LU factorization-based linear solver in OCTAVE and to\n",
    "evaluate its accuracy for various test matrices. The solver consists of computing the LU\n",
    "decomposition of a square $n×n$ double precision matrix $A$ such that $A = LU$ with lower\n",
    "triangular $L$ and upper triangular $U$ and subsequent forward and back substitution. In\n",
    "particular:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part I - LU Decomposition (3 points)\n",
    "First implement the standard \"scalar\" (unblocked) algorithm (i.e. three nested loops)\n",
    "with partial pivoting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random non-singular matrix.\n",
    "function A = generate_random_nonsingular_matrix(n)\n",
    "    A = rand(n);\n",
    "end\n",
    "\n",
    "# Calculate L, U and P for LU decomposition of non-singular matrix A.\n",
    "function [L, U, P] = decompose_matrix(A, n)\n",
    "    for k = 1:n - 1\n",
    "        # Fetch all elements we want to investigate to find |a_pk| >= |a_ik| -> index of maximum on or below the diagonale.\n",
    "        [p_value, p_index] = max(A(k:n, k));\n",
    "        \n",
    "        # Swap rows if there is a bigger value underneath the diagonale.\n",
    "        if p_index != k\n",
    "            A([p_index, k], :) =A([k, p_index], :);\n",
    "        end\n",
    "        \n",
    "        #if A[k, k] != 0\n",
    "        #end\n",
    "    end\n",
    "end\n",
    "\n",
    "n = 100;\n",
    "A = generate_random_nonsingular_matrix(n);\n",
    "decompose_matrix(A, n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part II - Solving a Triangular Linear Systems (1 point)\n",
    "1. Forward substitution: Write a routine which solves a given $n×n$ lower triangular linear system $Lx = b$ for $x$.\n",
    "2. Back substitution: Write another routine which solves a given $n × n$ upper triangular linear system $Ux = b$ for $x$.\n",
    "3. Evaluate the accuracy of your codes for increasing n in terms of the relative residual and the relative forward error. (For the definition of relative residual and relative forward error please see Part III!)  \n",
    "  \n",
    "For these experimental evaluations, use randomly generated (non-singular) $L$ and $U$ and determine $b$ such that the exact solution $x$ is a vector of all ones: $x = (1; 1; ...; 1; 1)T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part III - Numerical Accuracy of LU-Based Linear Solver (4 points)\n",
    "\n",
    "The main purpose of this part is to experimentally evaluate the numerical accuracy of\n",
    "the linear systems solver you implemented in Parts I and II for different test matrices\n",
    "and to compare it with the built-in solver from OCTAVE. You can solve a linear system\n",
    "Ax = b for x using the n operator (e.g. x = A n b).\n",
    "\n",
    "1\\. Take your LU factorization from Part I and combine it with your triangular linear systems solvers from Part II in order to get a complete LU-based linear solver.  \n",
    "  \n",
    "2\\. Input data for your experiments:  \n",
    "a) Generate random test matrices S with entries uniformly distributed in the interval $[-1,1]$.  \n",
    "b) Generate test matrices H which are defined by $$H_{ij} := \\frac{1}{i + j − 1}\\;for\\;i = 1;...;\\;n\\;and\\;j = 1; ...; n.$$  \n",
    "c) In all your test cases, determine the corresponding right hand side b of length n such that the exact solution x of the linear system is a vector of all ones: $x = (1; 1; : : : ; 1; 1)^T$.  \n",
    "\n",
    "3\\. Solve the linear systems $Sx = b$ and $Hx = b$ with your LU-based linear solver and the built-in OCTAVE solver and evaluate the numerical accuracy of the computed solution.  \n",
    "a) Problem sizes: Start with $n = 2; 3; 4; 5; ...;10$ then incease in increments of 5. For $n > 50$ you can further increase the increment. The largest value of $n$ should be as large as possible (so that your code terminates within a reasonable time).  \n",
    "\\tb) Accuracy: For the computed solution ^ x, evaluate the relative residual r:\n",
    "$$r := \\frac{||M\\hat{x} - b||_1}{||b||_1} $$\n",
    "($M$ is $S$ or $H$) as well as the relative forward error $f$:\n",
    "$$f := \\frac{||\\hat{x} - x||_1}{||x||_1} $$\n",
    "\n",
    "4\\. For both your and the OCTAVE solver generate the following plots for the different\n",
    "test matrices:\n",
    "a) Relative residual and relative forward error in $\\hat{x}$ vs. $n$: One figure for both accuracy metrics for matrix type $S$, another figure for both accuracy metrics for matrix type $H$.\n",
    "\n",
    "5\\. Interpret and explain your experimental results in your report. Do you think that there is a fundamental difference in the numerical accuracy which your LU-based linear solver achieves for the two types of test matrices? If yes, explain the reasons for this difference. How does your solver compare to the OCTAVE version?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
